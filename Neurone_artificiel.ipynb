{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XavierCachan/moduleIA_S4/blob/main/Neurone_artificiel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Retour vers la partie 2 : Caractérisation d'une batterie par optimisation](https://colab.research.google.com/drive/1JXGgboVAfwCTm1tow6axvQS3vtgH3vH3#scrollTo=4B-_OgfjO2Ab)"
      ],
      "metadata": {
        "id": "4B-_OgfjO2Ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TP IA Partie 3 - Caractérisation d'une batterie par un neurone artificiel - IUT de Cachan GEII2 2024**\n",
        "XM - Février 2024 - Version : 0.5\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "xYl_UBCdxmOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : Pour avancer dans ce notebook, il suffit d'exécuter (petite flèche), ou compléter puis exécuter, les différents blocs de code placés ci-dessous."
      ],
      "metadata": {
        "id": "32LUF88XLElJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour cette troisième partie, nous allons traiter le même problème de carctérisation de batterie que dans la partie 2, mais cette fois en utilisant les modules Python permettant de créer des neurones artificiels. Le modèle recherché est donc toujours **U_bat = E - Ri * I_bat**  "
      ],
      "metadata": {
        "id": "Qt1QKJmpPe9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Import des modules nécessaires pour les calculs et l'affichage**"
      ],
      "metadata": {
        "id": "UxOEtnP_zxMB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VwTK_rnwWGs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd               # Module pour la construction d'un réseau de neurones\n",
        "import tensorflow as tf           # TensorFlow est LE module utilisé pour l'entrainement d'un réseau de neurones\n",
        "import numpy as np                # Module de fonctions mathématiques\n",
        "import matplotlib.pyplot as plt   # Module pour l'affichage"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Fabrication des signaux de mesure de tension U_mes (ce sont les mêmes codes que dans la Partie 2)**"
      ],
      "metadata": {
        "id": "SxHma1Md1gO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 40                           # Nombre de mesures\n",
        "I_bat = np.linspace(0,10,num=N)  # Fabrication d'un vecteur de N points régulièrement espacés entre 0 et 10 (0, 0.25, 0.5,...9.75 Ampères)\n",
        "\n",
        "# Définition de la fonction mathématique théorique. Le modèle que l'on va essayer de retrouver automatiquement est U_bat = E - Ri * I_bat\n",
        "Ri_th = 0.15                   # Poids théorique à trouver. Par défaut 0.15 ohms\n",
        "E_th = 12                      # Biais théorique à trouver. Par défaut 12 V\n",
        "U_th = E_th - Ri_th * I_bat     # Valeurs des tensions si la mesure est \"parfaite\""
      ],
      "metadata": {
        "id": "nZMA_gKbyP7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour rendre le cas plus réel, on ajoute du bruit de mesure"
      ],
      "metadata": {
        "id": "BdYfJg_1K1Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = 0.3             # \"Intensité\" de bruit\n",
        "bruit = sigma*(np.random.randn(len(U_th)))\n",
        "U_mes = U_th + bruit    # Signaux de mesure \"réels\" = signaux parfaits + bruit"
      ],
      "metadata": {
        "id": "Ve3LzM2a4R3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage des mesures\n",
        "fig,ax = plt.subplots(1,figsize=(8,5))\n",
        "ax.plot (I_bat, U_mes, marker=\"+\", linestyle=\"none\", linewidth=1, label=\"Tension réelle mesurée\")\n",
        "ax.plot (I_bat, U_th, linestyle=\"--\", linewidth=0.5, label=\"Droite parfaite (ce que l'on souhaite retrouver)\")\n",
        "ax.set_title(\"Mesures sur la batterie\")\n",
        "ax.set_xlabel(\"Entrées Courant I_bat\")\n",
        "ax.set_ylabel(\"Tension U_bat\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1VN0u6k7yJcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Recherche des paramètres de la batterie avec un neurone**"
      ],
      "metadata": {
        "id": "0XByvgWP5_Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un neurone artificiel (voir dessin ci-dessous) associe des poids w à chacune de ses entrées x (=caractéristiques), et ajoute un biais b. On peut ensuite ajouter une fonction d'activation f pour obtenir la sortie y (=étiquette). Si l'on prend une seule entrée, et pas de fonction d'activation, on retrouve le y = w * x + b de la partie 2 !"
      ],
      "metadata": {
        "id": "3s8gVUOMo9D4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div>\n",
        "<img src=\"https://user.oc-static.com/upload/2018/12/10/15444553183515_neuroneformel-1.png\" width=\"500\"/>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "DCKHYBxKojdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour travailler avec un réseau de neurones, il faut commencer par écrire **une fonction pour définir le réseau** : nombre de couches, type de couche, nombre de neurones par couches, ... Ici pour cette première approche un seul neurone est suffisant pour retrouver une équation y = w * x + b pour laquelle on espère obtenir après entrainement w = -Ri_th et b = E_th."
      ],
      "metadata": {
        "id": "8xJMlpsALV-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour contruire un modèle de régression linéaire\n",
        "def construction(taux_apprentissage):\n",
        "  modele = tf.keras.models.Sequential()  # Définition d'un modèle de réseau séquentiel (= ensemble de couches)\n",
        "\n",
        "  # Description du réseau : ici 1 couche de 1 neurone, et pas de fonction d'activation\n",
        "  # Une couche \"Dense\" signifie une couche de neurones artificiels\n",
        "  # D'autres types de couches sont possibles : layers.Rescaling(), layers.Conv2D(), layers.MaxPooling2D(), layer.Dropout()... comme vu dans le cours\n",
        "  modele.add(tf.keras.layers.Dense(units=1,             # unit = le nombre de sorties de la couche, donc le nombre de neurones\n",
        "                                  input_shape=(1,)))    # 1 car la couche n'a qu'une seule entrée x (une valeur de courant I_bat) pour notre exercice\n",
        "\n",
        "  # Finalisation du réseau : on précise les paramètres d'apprentissage,  et\n",
        "  modele.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=taux_apprentissage),  # Le type d'optimiseur (RMSprop) et le taux d'apprentissage\n",
        "                loss=\"mean_squared_error\",                                                              # L'erreur à minimmiser (ici moyenne des distances au carré)\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])                                      # Une grandeur quantifiant la qualité de l'apprentissage\n",
        "                                                                                                        # Ici c'est directement la racine carré de l'erreur\n",
        "                                                                                                        # (pour ceux qui sont à l'aise, c'est la valeur efficace de la distance)\n",
        "  return modele"
      ],
      "metadata": {
        "id": "N6pb29s56od1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On doit ensuite écrire la fonction qui permettra d'**entrainer le réseau**.  \n",
        "- On dispose pour cela d'exemples de couples entrées/sorties \"connus\", que nous utiliserons comme **base d'apprentissage**. Pour nous, un couple c'est une de nos mesures, c'est à dire une valeur de tension U_bat mesurée pour un courant I_bat donné. La base d'apprentissage, c'est donc les 40 mesures (40 tensions U_bat pour 40 courants I_bat) présentées précédemment.  \n",
        "- \"**Entrainer**\", cela signifie modifier les poids w et les biais b des neurones afin que pour une entrée donnée la sortie soit la meilleure possible. Le réseau modifie au fur et à mesure les poids/biais à partir des données entrées/sortie que nous lui fournissons en exemple afin qu'au final ça \"colle\" au mieux à tous ces exemples.  \n",
        "\n",
        "La fonction d'entrainement a besoin de plusieurs arguments qu'il faut bien comprendre :"
      ],
      "metadata": {
        "id": "g5BOz4Y9LqeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour entrainer le modèle par régression linéaire\n",
        "def entrainement(modele, feature, label, epochs, batch_size):\n",
        "  # On fournit en arguments :\n",
        "  # - modele : le réseau à entrainer\n",
        "  # - feature : les \"caractéristiques\" d'entrée (x)\n",
        "  # - label : les \"étiquettes\" de sortie (y)\n",
        "  # - epochs : le nombre d'itérations de l'entrainement\n",
        "  # - batch_size : le nombre de caractéristiques prises en compte dans une itération (entre 1 et le nb total disponible)\n",
        "  # Par ex. si batch_size = 10, alors on utilise seulement les 10 premiers couples entrées/sorties de notre base d'apprentissage, puis les 10 suivants à l'itération 2...\n",
        "\n",
        "  history = modele.fit(x=feature,     # Fonction TensorFlow d'entrainement du réseau\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs)\n",
        "\n",
        "  # Récupération des poids et biais calculés pour notre neurone\n",
        "  trained_weight = modele.get_weights()[0]\n",
        "  trained_bias = modele.get_weights()[1]\n",
        "\n",
        "  # Récupération de la liste des itérations\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Récupération de l'erreur pour chaque itération\n",
        "  rmse = pd.DataFrame(history.history)[\"root_mean_squared_error\"]\n",
        "\n",
        "  return trained_weight, trained_bias, epochs, rmse"
      ],
      "metadata": {
        "id": "8Ibqk1XcLrGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On définit les paramètres de l'entrainement avant de le lancer :"
      ],
      "metadata": {
        "id": "e9jyTteKMG0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taux_apprentissage=0.01   # \"Vitesse\" d'apprentissage. Par défaut 0.01\n",
        "epochs=400                # Nombre d'itérations pour l'entrainement. Par défaut 400\n",
        "batch=10                  # Nombre de caractéristiques prises en compte dans une itération. Par défaut 10\n",
        "\n",
        "# Construction du réseau...\n",
        "mon_modele = construction(taux_apprentissage)\n",
        "\n",
        "# ... puis entrainement : à chaque itération il modifie les poids/biais pour que le modèle s'améliore\n",
        "# Notez ici que l'on n'a pas fourni de direction de descente !\n",
        "trained_weight, trained_bias, epochs, rmse = entrainement(mon_modele, I_bat,\n",
        "                                                         U_mes, epochs,\n",
        "                                                         batch)\n",
        "\n",
        "#Affichage de l'évolution de l'erreur\n",
        "fig,ax = plt.subplots(1,figsize=(8,5))\n",
        "ax.plot (epochs,rmse, linestyle=\"-\", linewidth=1, label=\"Erreur\")\n",
        "ax.set_xlabel(\"Itérations\")\n",
        "ax.set_ylabel(\"Valeur de l'erreur\")\n",
        "ax.set_xscale('log')\n",
        "ax.set_yscale('log')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "q1JyV82j6Hc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regardons ce que donne notre modèle pour l'intervale de courant ayant servi aux mesures :"
      ],
      "metadata": {
        "id": "RWt_K4K4ITxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse du modèle obtenu pour notre réseau après apprentissage\n",
        "U_mod = trained_bias + (I_bat * trained_weight) # B + W * I_bat\n",
        "\n",
        "# Affichage des résultats du modèle\n",
        "# Affichage des résultats du modèle\n",
        "fig,ax = plt.subplots(1,figsize=(8,5))\n",
        "ax.plot (I_bat, U_th, linestyle=\"--\", linewidth=0.5, label=\"Tension parfaite\")\n",
        "ax.plot (I_bat, U_mes, marker=\"+\", linestyle=\"none\", linewidth=1, label=\"Tension réelle mesurée\")\n",
        "ax.plot (I_bat, U_mod[0], linestyle=\"-\", linewidth=1, color=\"red\", label=\"Droite optimisée\")\n",
        "ax.set_title(\"Résultats du réseau\")\n",
        "ax.set_xlabel(\"Entrées Courant I_bat\")\n",
        "ax.set_ylabel(\"Tension U_bat\")\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "print (\"Les paramètres théoriques sont : E_th = \" + str(E_th) + \"V et Ri_th = \" + str(Ri_th) + \"ohms \")\n",
        "print (\"Les paramètres calculés par le modèle en \" + str(len(epochs)) + \" itérations sont E_mod = \" + str(trained_bias[0]) + \"V et Ri_mod = \" + str(-trained_weight[0][0]) + \"ohms \")\n"
      ],
      "metadata": {
        "id": "bpsaFaQeIZ6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La droite optimisée n'est pas si mauvaise, mais nous avons déjà obtenu des résultats similaires dans la partie 2... sauf qu'il faut se souvenir que là nous n'avons pas fourni l'expression de la pente : le réseau a appris tout seul, \"sur le tas\" !  \n",
        "Le problème ici est aussi que les ordres de grandeurs des paramètres que l'on veut optimiser sont très différents : la valeur de la pente w est ~100x plus faible que le biais b car la résistance interne de la batterie est très faible. Les choses pourraient s'améliorer en normalisant les caractéristiques d'entrée, comme nous le verrons par la suite.  \n",
        "Un autre point remarquable : il y a de l'aléatoire dans les résultats obtenus : comparez avec vos camarades, ou réentrainez le réseau et vous verrez que ce dernier obtiendra une autre droite !"
      ],
      "metadata": {
        "id": "PaKkvk0IJ916"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enfin, on teste généralement un réseau de neurones sur une base \"non connue\" (non utilisée pour l'apprentissage) afin de vérifier qu'il est capable de prédire une sortie pour une entrée qui n'a pas été apprise, par exemple ici pour un courant I_bat de 0.1 A, ou 10.6 A.  \n",
        "Comment faire ces tests sur une entrée qui n'a pas servi à l'apprentissage ?"
      ],
      "metadata": {
        "id": "FL8a6IUgAZ0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédiction sur des exemples non utilisés lors de l'apprentissage\n",
        "x_test = [0.1, 1.4, 10.6]     # valeurs de I_bat courants tests\n",
        "mon_modele.predict(x_test, verbose=0)"
      ],
      "metadata": {
        "id": "PcpElsHMAhE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédiction sur un exemple particulier de la liste\n",
        "choix = 2                     # valeur de I_bat à tester\n",
        "print (\"Notre modèle IA dit que la tension de sortie U_bat vaut \" + str(mon_modele.predict(x_test, verbose=0)[choix][0]) + \" V pour un courant de \" + str(x_test[choix]) + \" A\")"
      ],
      "metadata": {
        "id": "CJhZRtxiAwk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un neurone c'est sympa... mais ça limite un peu les choses ! => [Lien vers la partie 4 : Réseau de neurones artificiels](https://colab.research.google.com/drive/1dlNg6MqZYpc1VwPpx5fuTtkuDFD-Z3Fb#scrollTo=xYl_UBCdxmOC)"
      ],
      "metadata": {
        "id": "6A4v-Wcxf0xb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A COMPLETER AVEC PRISE EN COMPTE DE LA TEMPERATURE EN ENTREE 2  \n",
        "+ Fonction activation RELU / Sigmoid ? A TESTER"
      ],
      "metadata": {
        "id": "B4hAsQWYZaJt"
      }
    }
  ]
}