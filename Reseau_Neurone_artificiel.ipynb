{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XavierCachan/moduleIA_S4/blob/main/Reseau_Neurone_artificiel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Retour vers la partie 3 : Caractérisation d'une batterie par un neurone artificiel](https://colab.research.google.com/drive/1O0b8AnUaOWrjGoY7RDKRmHjWr2QeJZ_Z#scrollTo=PaKkvk0IJ916)"
      ],
      "metadata": {
        "id": "4B-_OgfjO2Ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TP IA Partie 4 - Réseau de neurones artificiels pour la classification - IUT de Cachan GEII2 2024**\n",
        "XM - Février 2024 - Version : 0.3\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "xYl_UBCdxmOC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : Pour avancer dans ce notebook, il suffit d'exécuter (petite flèche), ou compléter puis exécuter, les différents blocs de code placés ci-dessous."
      ],
      "metadata": {
        "id": "32LUF88XLElJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour cette dernière partie du TP, nous allons attaquer un exercice plus complexe : traiter un problème de reconnaissance automatisée de chiffres écrits à la main, en utilisant la base de données MNIST ([lien Wikipedia](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST)). Cet exercice est (très) inspiré d'un exemple fourni par Google, que l'on peut retrouver [ici](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/multi-class_classification_with_MNIST.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=multiclass_tf2-colab&hl=fr#scrollTo=wDlWLbfkJtvu)."
      ],
      "metadata": {
        "id": "Qt1QKJmpPe9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rappel : Principe du codage d'une image**"
      ],
      "metadata": {
        "id": "8wjHfwkJIN5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette base de données, on trouve de nombreuses images d'apprentissage. Comme nous l'avons vu en S2, une image est codée en mémoire en donnant une valeur à chaque pixel, comme on peut le voir sur l'exemple ci-dessous d'une image 14x14 pixels :"
      ],
      "metadata": {
        "id": "69Cclci-jwlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Principe de codage d'un caractère écrit à la main.](https://www.tensorflow.org/images/MNIST-Matrix.png)"
      ],
      "metadata": {
        "id": "aZl8IWANiFz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans l'exercice qui va suivre, nos images ne font pas 14x14 mais 28x28 pixels (meilleure résolution). Chaque pixel est codé en niveau de gris par un entier 8 bits : 0 = blanc, 255 = noir. L'objectif de l'exercice sera donc d'arriver à entrainer un réseau de neurones capable de reconnaitre le chiffre entre 0 et 9 pour une image donnée."
      ],
      "metadata": {
        "id": "y1dXWsNilKze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Import des modules nécessaires pour les calculs et l'affichage**"
      ],
      "metadata": {
        "id": "UxOEtnP_zxMB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VwTK_rnwWGs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd         # Module pour la construction d'un réseau de neurones\n",
        "import tensorflow as tf     # TensorFlow est LE module utilisé pour l'entrainement d'un réseau de neurones\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Récupération des images d'entrainement et de test**"
      ],
      "metadata": {
        "id": "SxHma1Md1gO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La base d'images fournie dispose cette fois d'un très grand nombre d'exemples. On va en profiter : afin de vérifier la qualité de l'entrainement du réseau que l'on va mettre en place, la base de caractéristiques initiales est divisée en 2 parties :  \n",
        "- des images d'entrainement sur lequelles les poids/biais des neurones sont entrainés\n",
        "- des images de test, non intégrées à l'entrainement (et donc que le réseau ne \"connait\" pas), sur lequelles on pourra vérifier que l'entrainement est bon (ou pas)."
      ],
      "metadata": {
        "id": "G7Ez2f-DnYlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Récupération des caractéristiques (x) et des étiquettes (y) d'entrainement et de test\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "nZMA_gKbyP7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est alors possible de \"visualiser\" une image caractéristique x de la base et de voir l'étiquette associée y :"
      ],
      "metadata": {
        "id": "BdYfJg_1K1Ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Il y a \" + str(len(y_train)) + \" images d'entrainement et \" +  str(len(y_test)) + \" images de test\")\n",
        "\n",
        "# Visualisation de l'image caractéristique #1713 utilisée pour l'entrainement\n",
        "exemple = 1710    # Choix d'une caractéristique\n",
        "print(\"Exemple de la caractéristique \" + str(exemple) + \" dont l'étiquette vaut \" + str(y_train[exemple]))\n",
        "x_train[exemple]"
      ],
      "metadata": {
        "id": "Ve3LzM2a4R3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Normalisation des caractéristiques**"
      ],
      "metadata": {
        "id": "0XByvgWP5_Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme nous l'avons évoqué dans la partie 3, il est nécessaire d'effectuer un prétraitement des caractéristiques (x) avant de les fournir en entrée du réseau."
      ],
      "metadata": {
        "id": "8xJMlpsALV-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisation des caractéristiques x pour la base d'entrainement et la base de test\n",
        "x_train_norm = x_train / 255.0\n",
        "x_test_norm = x_test / 255.0"
      ],
      "metadata": {
        "id": "N6pb29s56od1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chaque pixel sera alors codé par un float entre 0 et 1."
      ],
      "metadata": {
        "id": "g5BOz4Y9LqeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pixel 12 de la colonne 10\n",
        "x_train_norm[exemple][10][12]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGMnbVpz-KJJ",
        "outputId": "5f0f5d82-2c31-4c23-adb5-90eab70ed9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10588235294117647"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Création du réseau de neurones artificiels**"
      ],
      "metadata": {
        "id": "MQanh6r_-nSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme dans l'exercice précédent, on commence par écrire la fonction définissant la topologie du réseau de neurones. Ce dernier est bien entendu plus complexe que celui à un seul neurone utilisé pour caractériser la batterie car :  \n",
        "- Pour la batterie : on fournissait **une** entrée (un courant) et le réseau devait nous trouver **une** sortie (la tension U_bat associée)\n",
        "- Pour la classification de chiffres : il a 28*28=784 entrées (les valeurs des pixels), et 10 sorties possibles (les chiffres de 0 à 9)"
      ],
      "metadata": {
        "id": "M3wKOnShFWeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour contruire un réseau de neurones, possiblement à plusieurs couches\n",
        "def construction(taux_apprentissage):\n",
        "  modele = tf.keras.models.Sequential()  # Définition d'un modèle de réseau séquentiel (ensemble de couches)\n",
        "\n",
        "  # On commence par une couche pour transformer les caractéristiques (28x28) en un tableau 1D de taille 28x28 = 784(on \"applatit\" le tableau 2D).\n",
        "  modele.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # Ajout d'une première couche cachée de 4 neurones, fonction d'activation \"Relu\"\n",
        "  modele.add(tf.keras.layers.Dense(units=4, activation='relu', input_shape=(784,)))    # Par defaut unit = 4\n",
        "\n",
        "  # Ajout d'une couche de régularisation type \"Dropout\" : on désactive aléatoirement 20% des neurones\n",
        "  modele.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "  # Ajout de la couche de sortie type \"softmax\", qui donne les probabilités associées à chaque étiquette possible\n",
        "  # Les étiquettes étant pour nous les chiffres de 0 à 9, nous avons obligatoirement 10 possibilités en sortie\n",
        "  modele.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "\n",
        "  # Construction du modèle à fournir à TensorFlow\n",
        "  # La fonction d'erreur \"crossentropy\" est adaptée pour des problèmes dits de classification multi-classe comme le notre (étiquettes de 0 à 9)\n",
        "  # L'optimiseur est Adam (c'était RMSprop dans l'exercice batterie)\n",
        "  modele.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=taux_apprentissage),\n",
        "                loss=\"sparse_categorical_crossentropy\",\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return modele"
      ],
      "metadata": {
        "id": "9DSwEwkO_SvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On définit ensuite la fonction d'entrainement utilisant TensorFlow."
      ],
      "metadata": {
        "id": "U02rTzd_Fflb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fonction pour entrainer le modèle de régression linéaire avec un petit nouveau : validation_split\n",
        "def entrainement(modele, feature, label, epochs, batch_size, validation_split):\n",
        "  # On fournit en arguments :\n",
        "  # - modele : le réseau à entrainer\n",
        "  # - feature : les \"caractéristiques\" d'entrée (x)\n",
        "  # - label : les \"étiquettes\" de sortie (y)\n",
        "  # - epochs : le nombre d'itérations (epochs)\n",
        "  # - batch_size : le nombre de caractéristiques prises en compte dans une itération (entre 1 et le nb total disponible)\n",
        "  # - validation_split (new!) : reserve une partie du lot caractéristiques/étiquettes d'entrainement pour évaluer le\n",
        "  # réseau en cours d'apprentissage. Ex : validation_split = 0.2 => 80% pour l'entrainement, 20% de validation (!! à ne pas confondre avec nos images de test !!)\n",
        "\n",
        "  history = modele.fit(x=feature,     # Fonction TensorFlow d'entrainement du réseau\n",
        "                      y=label,\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=epochs,\n",
        "                      shuffle=True,\n",
        "                      validation_split=validation_split)\n",
        "\n",
        "  # Récupération de la liste des itérations\n",
        "  epochs = history.epoch\n",
        "\n",
        "  # Récupération des information à chaque itération\n",
        "  hist = pd.DataFrame(history.history)\n",
        "\n",
        "  return epochs, hist\n"
      ],
      "metadata": {
        "id": "8Ibqk1XcLrGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On choisit les paramètres de l'entrainement et on construit la structure du réseau de neurones artificiels :"
      ],
      "metadata": {
        "id": "e9jyTteKMG0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "taux_apprentissage=0.003    # Par defaut 0.003\n",
        "epochs = 50                 # Par défaut 50\n",
        "batch_size = 4000           # Par défaut 4000\n",
        "validation_split = 0.2      # Par défaut 0.2\n",
        "\n",
        "# Construction du réseau...\n",
        "mon_modele = construction(taux_apprentissage)\n"
      ],
      "metadata": {
        "id": "WpmLYt5KXdhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il est alors possible de vérifier si la structure est ok, et de voir le nombre de paramètres (et donc la taille!) du réseau que nous créons par la commande *summary* :"
      ],
      "metadata": {
        "id": "bkekriyPXwM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mon_modele.summary()"
      ],
      "metadata": {
        "id": "7OmXeFt9XbNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expliquer pourquoi la couche dense que nous avons créée contient 3140 paramètres... pour seulement 4 neurones !"
      ],
      "metadata": {
        "id": "1V28GtbuYB5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Entrainement du réseau de neurones artificiels**  \n",
        "  \n",
        "Tout semble ok, on peut passer à l'entrainement :"
      ],
      "metadata": {
        "id": "OpIEI1llIQXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrainement\n",
        "epochs, hist = entrainement(mon_modele, x_train_norm, y_train,\n",
        "                            epochs, batch_size, validation_split)\n",
        "\n",
        "# Affichage de l'évolution du taux de prédiction\n",
        "fig,ax = plt.subplots(1,figsize=(8,5))\n",
        "ax.plot (epochs,hist['accuracy'], linestyle=\"-\", linewidth=1, label=\"Précision des prédictions\")\n",
        "ax.set_xlabel(\"Itérations\")\n",
        "ax.set_ylabel(\"Précision des prédictions\")\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q1JyV82j6Hc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La précision semble déjà pas trop mal pour notre petit réseau à 4 neurones. Il reste à le tester..."
      ],
      "metadata": {
        "id": "B5N5w-dqRTe-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Evaluation du réseau de neurones artificiels entrainé**"
      ],
      "metadata": {
        "id": "hEsHvvQ1IE-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation globale**  \n",
        "Le modèle obtenu peut alors être testé sur la partie de la base que nous avions initialement mise de côté pour la réserver aux tests. Elle est nommée (x_test, y_test) et n'a donc pas servi à l'apprentissage."
      ],
      "metadata": {
        "id": "RWt_K4K4ITxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse du modèle obtenu sur l'ensemble de la base de test pour obtenir la précision\n",
        "print(\"Evaluation du modèle sur l'ensemble de la base de test (donc non connue par le réseau) :\")\n",
        "print(\"(Regarder la valeur de accuracy, si elle vaut 1 c'est parfait!) \\n\")\n",
        "loss, acc = mon_modele.evaluate(x=x_test_norm, y=y_test, batch_size=batch_size)\n",
        "print(\"Précision obtenue : {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "id": "bpsaFaQeIZ6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation d'un individu**  \n",
        "Il est également possible d'obtenir la sortie du modèle pour une seule caractéristique x qui nous intéresse. Cette sortie contient donc pour chacune des 10 étiquettes la probabilité qu'elle soit \"la bonne\". Si tout se passe bien, la probabilité doit être maximale pour l'étiquette attendue."
      ],
      "metadata": {
        "id": "q7D_7vRyJVbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choisissons un exemple particulier de la base de test\n",
        "exemple = 5    # Choix d'une caractéristique de la base de test (rappel : taille = 10000)  # Par défaut = 5\n",
        "print(\"Exemple de la caractéristique \" + str(exemple) + \" de la base de test, dont l'étiquette à retrouver est \" + str(y_test[exemple]))\n",
        "x_test[exemple]"
      ],
      "metadata": {
        "id": "iiP6ulmEVKQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quelles probabilités nous prédit le modèle pour cette caractéristique d'entrée ?"
      ],
      "metadata": {
        "id": "GeekGpD3KYvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédiction sur un exemple particulier de la base de test\n",
        "mon_modele.predict(x_test, verbose=0)[exemple]"
      ],
      "metadata": {
        "id": "NvSuUzBcExM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si la probabilité est maximale pour l'étiquette que l'on cherche, c'est que la prédiction est bonne ! Sinon, c'est une erreur du modèle:...  \n",
        "Il ne reste donc plus qu'à trouver la probabilité maximale dans cette liste, et à afficher l'indice associé qui correspond directement à l'un des 10 chiffres possibles."
      ],
      "metadata": {
        "id": "LGx4JK0UKnTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recherche de l'indice de probabilité maximale\n",
        "#np.max(mon_modele.predict(x_test, verbose=0)[exemple])      # Recherche du max\n",
        "#np.argmax(mon_modele.predict(x_test, verbose=0)[exemple])   # Recherche de l'indice associé\n",
        "print (\"Notre modèle IA dit que le chiffre sur l'image est un : \" + str(np.argmax(mon_modele.predict(x_test, verbose=0)[exemple])))"
      ],
      "metadata": {
        "id": "z0km0c9DKz2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "8c2290c8-d0bd-42b6-8606-962ff0d81ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c72a1f7c5fc6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Recherche de l'indice de probabilité maximale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon_modele\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexemple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# Recherche du max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon_modele\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexemple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Recherche de l'indice associé\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Notre modèle IA dit que le chiffre sur l'image est un : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmon_modele\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexemple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testez pour une autre étiquette, par exemple l'étiquette 8 qui n'est vraiment pas simple à déchiffrer... même pour un humain ! (l'étiquette 18 est aussi assez difficile). Votre modèle propose-t-il une bonne prédiction dans ce cas ?"
      ],
      "metadata": {
        "id": "RV-O5yTyEvVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peut on connaître tous les nombres pour lesquels il y a une mauvaise prédiction ? Oui, mais c'est un peu long... Testons déjà sur les 100 premières images de la base de test :"
      ],
      "metadata": {
        "id": "lxeD5h0hIEBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Récupération des probabilités (y) pour les 100 premières images de la base de test\n",
        "y_pred = mon_modele.predict(x_test[0:100])\n",
        "error = []\n",
        "\n",
        "# Comparaison de la sortie à plus forte probabilité avec le chiffre attendu\n",
        "for i in range (1,100):\n",
        "  if np.argmax(mon_modele.predict(x_test, verbose=0)[i]) != y_test[i]:  # Si différence on ajoute à la liste\n",
        "    error.append(i)\n",
        "print(error)\n",
        "print (\"On a donc \" + str(len(error)) + \" erreur(s) de prédiction sur \" + str(len(y_pred)) + \" images de tests\")"
      ],
      "metadata": {
        "id": "rxi8shcLE-_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pourrait-on améliorer en mettant 32 neurones au lieu de 4 dans la couche cachée ? (il faut donc repartir du point 4. Création du réseau de neurones artificiels)"
      ],
      "metadata": {
        "id": "u9iAad6kNJwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pourrait-on encore l'améliorer en mettant 256 neurones dans la première couche cachée et en ajoutant une seconde couche cachée de 128 neurones ? (on laissera une couche de dropout après chacune des 2 couches)"
      ],
      "metadata": {
        "id": "86hJ4ZVYNc1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de tout cela, on peut bien entendu mettre en place des systèmes de prédiction sur des ensembles plus complexes, comme ceux qui ont été étudiés lors des précédentes séances de TP du module IA. A vous de jouer :-)"
      ],
      "metadata": {
        "id": "PaKkvk0IJ916"
      }
    }
  ]
}